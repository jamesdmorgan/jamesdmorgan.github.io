---
layout: post
title: OpsDev
description: "Thinking about production first"
modified: 2016-08-14
category: devops
tags: [devops,vagrant,docker,ansible,monitoring]
---

<section>
  <header>
    <h3>Contents</h3>
  </header>
<div id="drawer" markdown="1">
*  Auto generated table of contents
{:toc}
</div>
</section><!-- /#table-of-contents -->


## 80/20

A frustrating trend I witnessed many times at my previous company stemmed from the fact that many of the developers writing software never had to a) deploy, b) support and c) upgrade their applications in production. A new update would be released and there would be a release note and manual steps needed to move to the new version but this would be down to the customer / ops team or at worst the actual customer to figure out.

The whole DevOps movement has tried to address this issue and get developers thinking about production and not just throwing code over the fence. There shouldn't be a DevOps team as such but the DevOps principles should be understood and practiced by the development team. Developers should be aware of the pain points experienced by Operations and understand the requirements of the system in order to make the applications supportable. This can be as simple as ensuring certain events are logged correctly or that there are sufficient health checks.

Conversely Operations should have an understanding of the business drivers and the reason for the applications. They should be able to help the Developers to think about real world issues that need to be addressed in a production environments.

Instead of leaving important architectural decisions to the last minute they should be part of the design from the beginning. Topics such as **High Availability**, **Fault Tolerance**, **Service Discovery**, **Data Persistence**, **Centralised Logging** and  **Monitoring** are essential in modern applications and can be much more complicated if left to the last minute to implement.

There have been a number of [articles](https://dzone.com/articles/opsdev-is-coming) recently discussing this concept.

From that I wanted to build a demo system that emulates a production environment. It should facilitate all the topics mentioned above in the simplest way possible to demonstrate each concept. The demo should provide a framework for experimenting with new tools and technologies.

## Project Overview

> [https://github.com/jamesdmorgan/vagrant-ansible-docker-swarm](https://github.com/jamesdmorgan/vagrant-ansible-docker-swarm)

The project is available on [github](https://github.com/jamesdmorgan/vagrant-ansible-docker-swarm) and will be extended as new components are added. The name may change as there is more than just an automated swarm

Everything will be automated so it should be trivial to get working. At the moment it uses around 12Gb of Ram. This can be reduced by using a smaller number of Virtual Machines. I wanted to use at least 3 managers to demonstrate clustering of both Docker Swarm and Consul.

### Current Components

- **Vagrant** - Management of Virtualbox VMs
- **Ansible** - Provisioning of boxes
- **Docker 1.12** - Swarm creation on manager and worker boxes
- **Consul** - External DNS, K/V store and dashboard
- **Registrator** - Intended to register services [but doesn't currently work](https://github.com/gliderlabs/registrator/issues/443) with **1.12**
- **Consul-notifier** - Temporary replacement to **Registrator** for registering Docker Swarm Services

### [Roadmap](https://github.com/jamesdmorgan/vagrant-ansible-docker-swarm/blob/master/CHANGELOG.md)

- **RSyslog** - Log shipping for container logs -> **LogStash** / **filebeat**
- **LogStash** - Log file filtering
- **Elasticsearch** - Log file indexing
- **Kibana** - Log file UI

- **CollectD** - System metrics
- **cAdvisor** - Docker metrics
- **Riemann** - Metric filtering and processing
- **InfluxDB** - Metric storage
- **Grafana** - Metric dashboard

- **Flocker** - Volume management

### Data persistence

Docker swarm brings amazing potential and new problems. Having containers re-scheduled causes problems when there are volumes / data persistence. Cattle containers work well in this environment. More complicated containers running Databases or k/v stores need to treated carefully. In my example I have a couple of containers that fall into this category. Mongo currently can move about the swarm. This would not work in a production environment as data loss is totally unacceptable. The options seem to be. Either don't run in the Swarm, limit to specific hosts using constraints or use volume manager like [Flocker](https://clusterhq.com/flocker/introduction/). I will investigate this after I have centralised logging and monitoring.

I will write an individual post for each stage of the project. Starting with building the Virtual Machines with Vagrant & Ansible, through provisioning the Docker Swarm, service discovery, applications, logging and system monitoring.







